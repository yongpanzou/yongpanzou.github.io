# jemdoc: nofooter
# jemdoc: addcss{./css/bootstrap.min.css}
# jemdoc: addcss{./css/custom.css}
# jemdoc: addjs{./js/bootstrap.min.js}
# jemdoc: title{YONGPAN's Homepage}
{{<div class="container"><div class="row">
<div class="col-xs-2 col col-sm-2 col-md-1 col-lg-1"></div>
<div class="col-xs-8 col col-sm-8 col-md-10 col-lg-10" id="contentall">
	<div class="row">
		<div class="col-xs-2 col col-sm-2 col-md-1 col-lg-1"></div>
		<div class="col-xs-2 col col-sm-2 col-md-10 col-lg-10">	
		}}
~~~
{}{img_left}{./data/original.jpg}{photo}{125px}{171px}{}
= {{<span style="font-size:xx-large;font-family:Times New Roman;color:black;"><b>}}Yongpan Zou{{</b></span>}} {{<span style="font-size:xx-large;font-family:STXingkai;color:black;"><b>}}(邹永攀){{</b></span>}}
{{<font color=black><b>}}Assistant Professor{{</b></font>}} \n
[http://csse.szu.edu.cn/en/index College of Computer Science and Software Engineering] \n
[http://www.szu.edu.cn/2014/en/ Shenzhen University] \n
#Assistant Director, Engineering Research Center of Wireless Big Data and Future Network \n 
*Addr.:*Room 943\/720, Building of Computer Science, South Distrcit, Shenzhen University \n
*Email:* /yongpan\@szu.edu.cn/; *Tel.:* /075586934659/\n
[https://scholar.google.com.hk/ Google Scholar]\n
~~~



== Biography
I am currently an Assistant Professor in the [http://csse.szu.edu.cn/en/index College of Computer Science and Software Engineering] of [http://www.szu.edu.cn/2014/en/ Shenzhen University], since September 2017. I obtained my Ph.D in February 2017 in the [https://www.cse.ust.hk/ CSE Department] of [http://www.ust.hk/ HKUST], under the supervision of [http://www.cse.ust.hk/~ni/ Professor Lionel M. Ni]. Prior to this, I received my B.E in [http://clet.xjtu.edu.cn/index.htm School of Chemical Engineering and Technology], [http://en.xjtu.edu.cn/ Xi'an Jiaotong University] in July 2013.



== Research Interests
My research interest covers /Wearable and Mobile Computing/, /Human-computer Interaction/ and /Ubiquitous computing/. My vision is to develop new technologies, algorithms, and systems that enable smart sensing, provide intelligent services, and deliver novel applications. I draw on novel sensing \& computing technologies with /embedded system design/, /machine learning models/, /signal processing algorithms/, and /mathematical methods/ to solve real-world problems. I am now leading /Intelligent Perception and Mobile Computing/ Group.

== Academic News
- 2018\/09, our paper "ArmIn: Explore the Feasibility of Designing a Text-entry Application Using EMG Signals" is accepted by Mobiquitous 2018. The first author is a master student under my supervision.
- 2018\/08, our paper "BiLock: User Authentication via Dental Occlusion Biometrics" is accepted by Ubicomp 2018.
- 2018\/04, our Deomo paper "A Novel Finger-Assisted Touch-free Text Input System Without Training" is accpeted by Mobisys 2018. The first author is a master student under my supervision.
- 2018\/02, I am invited to be TPC member of Globecom 2018
#- 2017\/07, our paper "ABAid: Navigation Aid for Blind People using Acoustic Signals" is accepted by IEEE MASS 2017. The first author is a UG student under my supervision.
#- 2017\/07, I start a one-month academic visit to Professor Daqing Zhang's group in Peking University 
#- 2017\/06, our paper about Wi-Fi Radar is accepted by IEEE COMMAG.
#- 2017\/05, I am invited to serve as TPC member and pulication chair of ICPADS 2017.


== Selected Publications \[[./fullList.html Full List]\]
* indicates Corresponding Author

=== Conference Papers

~~~
{}{img_left}{./data/ArmIn.jpg}{photo}{150px}{100px}{}
*ArmIn: Explore the Feasibility of Designing a Text-entry Application Using EMG Signals*
\n Qiang Yang, {{<font color=LightSlateGray><b>}}Yongpan Zou*{{</b></font>}}, Meng Zhao, Jiawei Lin, Kaishun Wu \n
/in Proceedings of ACM Mobiquitous/, New York City, USA, 2018. \n
\[[./data/ArmInCamera.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/ArmInSlides.pdf {{<font color=navy><b>}}Slides{{</b></font>}}]\]\[[./data/tagFreebib.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~

~~~
{}{img_left}{./data/BiLock.jpg}{photo}{150px}{100px}{}
*BiLock: User Authentication via Dental Occlusion Biometrics*
\n {{<font color=LightSlateGray><b>}}Yongpan Zou{{</b></font>}}, Meng Zhao, Zimu Zhou, Jiawei Lin, Mo Li, Kaishun Wu \n
/In Proceedings of ACM Ubicomp/, vol.2, no.3, Singapore, Singapore, 2018. \n
\[[./data/BiLockCamera.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/BiLockSlides.pdf {{<font color=navy><b>}}Slides{{</b></font>}}]\]\[[https://youtu.be/IYdNcvU_uDs {{<font color=purple><b>}}Demo{{</b></font>}}]\]\[[./data/bilock.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~

~~~
{}{img_left}{./data/TagFree.jpg}{photo}{150px}{100px}{}
*TagFree: Passive Object Differentiation via Physical Layer Radiometric Signatures*
\n {{<font color=LightSlateGray><b>}}Yongpan Zou{{</b></font>}}, Yuxi Wang, Shufeng Ye, Kaishun Wu, Lionel M. Ni \n
/in Proceedings of IEEE Percom/, Hawaii, USA, 2017. \n
\[[./data/TagFree.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/TagFreeSlides.pdf {{<font color=navy><b>}}Slides{{</b></font>}}]\]\[[./data/tagFreebib.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~

~~~
{}{img_left}{./data/WiHear.jpg}{photo}{150px}{100px}{}
*We Can Hear You with WiFi!* \n
Guanhua Wang, {{<font color=LightSlateGray><b>}}Yongpan Zou{{</b></font>}}, Zimu Zhou, Kaishun Wu, Lionel M. Ni \n
/in Proceedings of ACM Mobicom/, Hawaii, USA, 2014. \n
\[[./data/WiHear.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/WiHearSlides.pdf {{<font color=navy><b>}}Slides{{</b></font>}}]\]\[[./data/wihearbib.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~


=== Journal Papers
~~~
{}{img_left}{./data/WiFiRadar.jpg}{photo}{150px}{100px}{}
*Wi-Fi Radar: Recognizing Human Behavior with Commodity Wi-Fi*
\n {{<font color=LightSlateGray><b>}}Yongpan Zou{{</b></font>}}, Weifeng Liu, Kaishun Wu, Lionel M. Ni \n
/in IEEE Communications Magazine/, Volume16, Issue 2, pp. 381-393, 2017. \n
\[[./data/wifiRadar.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[https://scholar.googleusercontent.com/scholar.bib?q=info:kPtDIPmyNoUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWSFzfTeSSQ0VSjdWB1BBjVsD9mVBa6S1&scisf=4&ct=citation&cd=-1&hl=zh-CN {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~

~~~
{}{img_left}{./data/GRfid.jpg}{photo}{150px}{100px}{}
*GRfid: A Device-free Gesture Recognition System Using COTS RFID Device*
\n {{<font color=LightSlateGray><b>}}Yongpan Zou{{</b></font>}}, Jiang Xiao, Jinsong Han, Kaishun Wu, Yun Li, Lionel M. Ni \n
/in IEEE Transactions on Mobile Computing/, Volume16, Issue 2, pp. 381-393, 2016. \n
\[[./data/GRfid.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/Grfidbib.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~


~~~
{}{img_left}{./data/SmartScanner.jpg}{photo}{150px}{100px}{}
*SmartScanner: Know More in Walls with Your Smartphone!* 
\n {{<font color=LightSlateGray><b>}}Yongpan Zou{{</b></font>}}, Guanhua Wang, Kaishun Wu, Lionel M. Ni \n
/in IEEE Transactions on Mobile Computing/, Vol. 15, Issue 11, pp. 2865-2877, 2016. \n
\[[./data/SmartScanner.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/Smartscannerbib.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~



=== Workshop\/Poster\/Demo
~~~
{}{img_left}{./data/EchoType.jpg}{photo}{150px}{100px}{}
*Demo: A Novel Finger-Assisted Touch-free Text Input System Without Training*
\n Qiang Yang, Hongrui Fu, {{<font color=LightSlateGray><b>}}Yongpan Zou*{{</b></font>}}, Kaishun Wu \n
/in Proceedings of ACM Mobisys/, Munich, Germany, 2018. \n
\[[./data/echotypeDemo.pdf {{<font color=crimson><b>}}Paper{{</b></font>}}]\]\[[./data/EchoTypePoster.pdf {{<font color=navy><b>}}Poster{{</b></font>}}]\]\[[https://youtu.be/9_OmofZM1Ic {{<font color=purple><b>}}Demo{{</b></font>}}]\]\[[./data/echotypeDemobib.txt {{<font color=green><b>}}BibTex{{</b></font>}}]\]
~~~

#== Projects
#~~~
#{}{img_left}{./data/Project-Behavicker.jpg}{photo}{150px}{100px}{}
#=== [https://yongpanzou.github.io/ Behavicker]
#The Indoor WiFi Radar Sense (IWRS) project is a system to detect, localize, and identify human motions and the environmental contexts using WiFi signals, such as human detection, line-of-sight condition identification, breath detection and lips reading.
#~~~

#~~~
#{}{img_left}{./data/Project-BiLock.jpg}{photo}{150px}{100px}{}
#=== [https://yongpanzou.github.io/ BiLock]
#The Indoor WiFi Radar Sense (IWRS) project is a system to detect, localize, and identify human motions and the environmental contexts using WiFi signals, such as human detection, line-of-sight condition identification, breath detection and lips reading.
#~~~


#== Research Funds
#- 基于声学感知的



== Professional Activities
- TPC Member for
-- IEEE Globecom 2017, IEEE ICPADS 2017, VTC 2018-Spring, IEEE Globecom 2018
- Reviewer for
-- ICPADS 2016, Ubicomp 2016, Globecom 2017, TMC, COMMAG, ToN
- Chairing service
-- Publication chair for ICPADS 2017 and ICPADS 2018

#== Teaching Experience
#- Wireless Sensor Network, Fall semester
#- Computer Network, Spring semester


== Group Members
- PG Students
-- Qiang Yang, Meng Zhao, since 2016
-- Yetong Han, Jiawei Lin, since 2017
-- Dan Wang, Baojie Yuan, sicne 2018
- UG Students
-- Hongrui Fu, Qianru Liao, Yuming Yang, Shicong Hong, Ziyin Wang, Yuhang Li, since 2017
- Alumni
-- Weifeng Liu (/now in CMB/), Shufeng Ye (/now in LONGTU GAME/), Changsheng Zhou (/now in CITIC Bank/), Junjun Bao (/now in CMB/), Xuejin Zhou (/now in JIGUANG/), since 2015
-- Jingchuan Xu (/now in Tencent/), Zehui Zheng (/now in University of Victoria with full scholarship/), Jinyong Wu (/now in Baidu/), since 2015

== Selected Teaching Achievements
- \[[./data/MCM.pdf MCM Award]\], \[[./data/huazi.jpg 华资杯]\], \[[./data/IoTCompetition.jpg 物联网大赛]\], \[[./data/Excellent.jpg 物联网大赛]\], \[[./data/fyprojectTeacher.jpg 百篇优毕]\], \[[./data/fyprojectStu.jpg 百篇优毕]\], \[[./data/Fit-mobile.jpg 移动终端设计大赛]\], \[[./data/input-mobile.jpg 移动终端设计大赛]\], \[[./data/huawei.jpg 华为杯]\]



{{
	</div>
	<div class="col-xs-2 col col-sm-2 col-md-1 col-lg-1"></div>
	</div>
	</div><div class="col-xs-2 col col-sm-2 col-md-1 col-lg-1"></div></div>}}
